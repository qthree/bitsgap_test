- `Начинаем получать RT (на бирже Trades) по WS и собирать новые KL`
    - Получать KL по WS или вычислять их самому на основе RT?

- `Список таймфреймов – 1м, 15м, 1ч, 1д`
    - Хранить в базе KL для каждого интервала?
    - Или хранить только для 1м, а для других вычислять на лету в запросе к БД? Если БД такое позволяет.
    - Или хранить вообще только RT и на основе их вычислять какждый раз?
    - Лучшее решение зависит от того как часто будут запросы к 1ч-1д KL, если часто то лучше хранить их
        - Чтобы каждый раз заново не рассчитывать
        - Всё равно место в БД 1ч-1д будут занимать сильно меньше чем 1м KL
        - Сохраняем 1ч-1д KL, можно оптимизировать потом.
    - Так же завист от количества RT в минуту
        - Если часто будут минуты когда не было ни одной сделки - будет сохраняться много "пустых" KL
            - Надо ли сохранять эти пустые KL?
            - Сохраняем пустые KL, можно оптимизировать потом.
        - Если будет слишком много запросов в минуту, то даже 1м KL будет дорого рассчитывать
            - Сохраняем 1м-15м, можно будет оптимизировать потом.
    - В тестовом проекте не идёт речь о запросах данных из БД, только о наполнении её данными.
        - В любом случае, пока заполняем БД всеми пришедшими данными
        - т.к. единственный способ проверить корректность данных пока - с помощью сторонних инструментов БД
            - и тестов?
            - Было бы неплохо написать тесты для проверки содержимого БД, хоть чтение из БД в проект не входит
            - Получается придётся в любом случае добавить минимальную реализацию чтения из БД?

- В интервью просили сделать решение "масштабируемым"
    - Если речь о производительности
        - Rust и Tokio уже предоставляют удовлитворительную производительность, а точнее минимальный overhead
        - Предусмотреть использование БД которую можно масштабировать
            - Количество операций записи не будет зависеть от количества пользователей агрегатора
                - Не требуется возможность писать в разные инстансы БД
                - Не требуется алгоритм консенсуса
                - Достаточно чтобы данные текли от основного инстанса в зеркала
            - Нужно изучить характер данных
                - Возможно в реальном проекте вместо масштабирования БД можно будет обойтись (частично?) кэшированием данных in-memory приложения
            - В интервью спрашивали про знания о Tarantool
                - Есть планы использовать его в реальном проекте?
                - Можно попробовать использовать его
            - Предусмотреть возможность использовать разных БД в качестве бэкенда для хранения данных?
                - Можно отрефакторить потом при надобности
                - Слишком out-of-scope
                - Трудно заранее сформулировать подходящий уровень абстракции для абсолютно разных БД (MongoDB vs PostreSQL, например)
        - В тестовом проекте не идёт речь о запросах данных из БД, только о наполнении её данными
            - Производтельность получение данных от API бирж никак не зависит от количества пользователей агрегатора, и в целом не является проблемой.
            - Заботиться о производительности придётся только при имплементации REST API агрегатора и чтения из БД
    - Если речь о использовании API разных бирж
        - Предусмотреть струтктуру проекта которая позволяет подключать новые биржи
            - с наименьшим boilerplate
            - при этом инкапсулировать переиспользуемые код и код для разных бирж

- Структура проекта
    - Библиотека с общим кодом
        - В общей библиотеке должны быть универсальные типы которые сохраняются в БД, с сигнатурой как в ТЗ
        - Можно принить к этим универсальным типам derive serde::Serialize, если нужна сериализация в JSON
            - Eсли будем отдавать их по своему REST API в полноценном проекте
            - Если будем сохранять как json в БД (MongoDB?)
    - По отдельной библиотеке на каждую биржу, зависят от общей библиотеки
        - В отдельных библиотеках живут типы специфичные для соответствующего REST API
        - Применяем к этим специфичным типам derive serde::Deserialize чтобы парсить ответ от REST API
        - Можно конвертировать специфичные типы в универсальный с помощью моего крейта derive_convert
    - Исполняемый крейт для получения и сохранения данных
        - Включает в себя крейты всех бирж, который можно включать/выключать при компиляции (features) и в рантайме (конфиг)
    - В будущем возможны другие исполняемые крейты которые будут выполнять функции (чтение из БД, торговые операции)
        - которые смогут переиспользовать те же библиотеки с общим кодом и с кодом специфичным для бирж

- Типы данных
    - В реальном проекте стоит обсудить использование внутренних типов вместо String
    - Строгая типизация поможет избежать логических ошибок
        - Сделает невозможным хранить в памяти невалидный стейт
        - После первичного парсинга мы будем уверены что данная запись всегда валидна
    - Нужно понять какие типы должны иметь возможность меняться/дополняться без перекомпиляции
    - `struct RecentTrade`
        - `tid: String` -> тип гарантирующий валидный формат Id
        - `pair: String` -> `(String, String)`, опционально с обёрткой, которая гарантирует что мы поддерживаем такую валютную пару
        - `price: String` и `amount: String` -> число не с плавающей точкой
            - см. crate [`fastnum`](https://docs.rs/fastnum/latest/fastnum/)
            - или [`Ratio<i128>`](https://docs.rs/num/latest/num/rational/struct.Ratio.html) в `num`
        - `side: String` -> `enum Side { Buy, Sell }`
        - `timestamp: i64` -> обёртка с методами для конвертации в типы данных из std/time/chrono
    - `struct Kline`
        - `time_frame: String`
            - Фиксированные значения -> `enum TimeFrame { Minute, Minute15, Hour, Day }`
            - Динамическое значение (мы не знаем какие могут быть TF на будущих биржах) -> аналог `Duration`
        - `o, h, l, c, volume_bs`: `f64` -> число не с плавающей точкой?
            - или лучше прокинуть насквозь как есть, чтобы избежать потерь при конверсии туда-обратно?
    - При сохранении в БД можно сохранять по прежнему как String
        - т.е. эти изменения никак не коснутся результата в БД, только организацию внутри программы
    - в ТЗ указаны конкретные сигнатуры типов, оставим пока как есть, без парсинга String, потом можно отрефакторить.
